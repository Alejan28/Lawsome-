{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model_name = \"readerbench/RoGPT2-medium\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "input_text = \"Genereaza un contract de vanzare cumparare \"\n",
        "input_ids = tokenizer(input_text, return_tensors=\"pt\")\n",
        "\n",
        "outputs = model.generate(**input_ids, max_new_tokens=50)\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "ycuaNRtbr3J1",
        "outputId": "8d587a00-13e7-4bf2-ba20-ba65fec507d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/563 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f135993c046d489ea8b145e30cb2e3e0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/869 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7f9305096c464a44bcc906c3771022f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5dfc2619283f467c9d91e3b33c1df90e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1fe6a3ed6b71423c9e451d494b67d81d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/357 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d0324481e1049fb8e371c303856fbd4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/1.44G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1016c1d5d994404ab687fff5099a5e8b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.44G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "989893ff76374d0684e98fc30e596025"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Genereaza un contract de vanzare cumparare  cu o companie de transport maritim.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model.config.pad_token_id = model.config.eos_token_id\n",
        "\n",
        "prompt = \"\"\"Redactează un contract de prestări servicii între două părți:\n",
        "1. Firma Alpha SRL\n",
        "2. Persoana fizică Ion Popescu\n",
        "\n",
        "Contractul trebuie să includă:\n",
        "- Obiectul contractului\n",
        "- Durata\n",
        "- Plata\n",
        "- Obligațiile părților\n",
        "- Semnături\n",
        "\"\"\"\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True)\n",
        "outputs = model.generate(\n",
        "    **inputs,               # includes both input_ids and attention_mask\n",
        "    max_new_tokens=300,\n",
        "    temperature=0.8,\n",
        "    top_p=0.9,\n",
        "    do_sample=True\n",
        ")\n",
        "\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "km4ZItpIwvFm",
        "outputId": "6cffea7a-4b65-4f84-9640-8ad2dc347768"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Redactează un contract de prestări servicii între două părți:\n",
            "1. Firma Alpha SRL\n",
            "2. Persoana fizică Ion Popescu\n",
            "\n",
            "Contractul trebuie să includă:\n",
            "- Obiectul contractului\n",
            "- Durata\n",
            "- Plata\n",
            "- Obligațiile părților\n",
            "- Semnături\n",
            "- Dovada că firma a fost selectată  pentru a presta  servicii  contractate  se face prin semnarea unui  acord  care trebuie să includă  declarațiile  și  documentele justificative.  La semnarea contractului, firma va semna un  acord  de prestari servicii  în care  se va preciza că  va furniza  serviciile  contractate  pentru  care a fost selectată  pentru a presta  servicii  contractate  pentru  care firma a fost selectată  pentru a presta  servicii  contractate  pentru  care firma a fost selectată  pentru a presta  servicii  contractate  pentru  care firma a fost selectată  pentru a presta  servicii  contractate  pentru  care firma a fost selectată  pentru a presta  servicii  contractate  pentru  care firma a fost selectată  pentru a presta  servicii  contractate  pentru  care firma a fost selectată  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Intrebare: Cum arata un model de vanzare cumparare?\n",
        "Raspuns:\n",
        "\"\"\"\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True)\n",
        "outputs = model.generate(\n",
        "    **inputs,               # includes both input_ids and attention_mask\n",
        "    max_new_tokens=300,\n",
        "    temperature=0.8,\n",
        "    top_p=0.9,\n",
        "    do_sample=True\n",
        ")\n",
        "\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fh9xRdiQy-wd",
        "outputId": "67b6a511-0b8b-47fd-be7f-22960c1d42c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intrebare: Cum arata un model de vanzare cumparare?\n",
            "Raspuns: \n",
            "Un model de vanzare este un model de vanzare care descrie modul în care un client poate sa cumpere produsele sau serviciile unui alt client. Aceste modele de vanzare sunt in general concepute pentru a fi intelese de catre cumparatori. Modelele de vanzare pot fi vizualizate si studiate de catre un consultant care poate identifica cele mai bune modele de vanzare. Modelele de vanzare sunt adesea folosite in comertul online pentru a fi oferite cumparatorilor si pentru a oferi o imagine de ansamblu asupra comportamentului de cumparare si asupra modului in care clientul ar trebui sa se comporte in anumite situatii de vanzare.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"Intrebare: Genereaza un contract de vanzare cumparare.\n",
        "Raspuns:\n",
        "\"\"\"\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True)\n",
        "outputs = model.generate(\n",
        "    **inputs,               # includes both input_ids and attention_mask\n",
        "    max_new_tokens=300,\n",
        "    temperature=0.8,\n",
        "    top_p=0.9,\n",
        "    do_sample=True\n",
        ")\n",
        "\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POj5L_nFzOnq",
        "outputId": "66d90aa2-d4d3-4b51-c550-45ce352a3702"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intrebare: Genereaza un contract de vanzare cumparare.\n",
            "Raspuns: \n",
            "În baza contractului de vânzare cumparare, گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه گه\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets accelerate torch\n"
      ],
      "metadata": {
        "id": "dfp3cVUAGX7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6ee54ee-b0d2-4e60-a961-eb54692d9fe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"json\", data_files=\"dataset.json\")\n",
        "\n",
        "# Optionally split into train/test\n",
        "dataset = dataset[\"train\"].train_test_split(test_size=0.1)\n",
        "\n",
        "#load tokenizer and model\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model_name = \"readerbench/RoGPT2-medium\"  # or your chosen RoGPT model\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Some GPT2 variants have no pad token — fix that:\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n"
      ],
      "metadata": {
        "id": "L9fSbOzaG1Sl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2240f2d-4f10-4a93-b2c4-ef504a0bbe56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(50258, 1024)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_example(example):\n",
        "    return f\"<|startoftext|>\\nÎntrebare: {example['question']}\\nRăspuns: {example['answer']}\\n<|endoftext|>\"\n",
        "\n",
        "def tokenize_function(example):\n",
        "    text = format_example(example)\n",
        "    tokens = tokenizer(\n",
        "        text,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=512,\n",
        "    )\n",
        "    tokens[\"labels\"] = tokens[\"input_ids\"].copy()  # language modeling\n",
        "    return tokens\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "ab117bdff97c4868acacb0c83b6b8672",
            "5a72f207885448828648cd77019ae8f9",
            "fe176c9a0560465eb36948d54c270f2e",
            "0e0793b0e1f94626959f7430dd0e8d12",
            "e0283ef8978b4e49b6a2fe5305366f39",
            "428456ddd1474abead039621cca33c8f",
            "dfafcc6612374446a1bd1d84421d6ffa",
            "ab9a1d49a3f94b86b1c44b688c463b1c",
            "e210264e2acd47b99c5e1e03f88d2151",
            "1e03d42338c442bd87fcdbc57629aaa4",
            "cce50da3527f427b9ee108f7b05211f7",
            "22ccc38c266846cda6a93653f25a3f05",
            "5a8deb24630b423eb6174ffd8565e727",
            "a945762d606b44a78b608e5dc912b7d2",
            "aa8dadcbb77a48e7b7e9375a72fc87bf",
            "30c6d1335d174ff2a367db204969f370",
            "e0077d36ac694aa5ac72b1548eebac9f",
            "8a8fa4f558cc4e67aaa0247b75c28805",
            "1aeba5885c294e118d7123d8e1ffd191",
            "262e98afeec548ecb83cca05783f0532",
            "0260d5ad3daf4e9a9350c066d4088c3a",
            "0d71c21a149f4c9fb5e1f0ab9e3ec6c3"
          ]
        },
        "id": "doMM8VpuLK2e",
        "outputId": "8de934bd-9a91-482c-d9e1-916d2785bf01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/108 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab117bdff97c4868acacb0c83b6b8672"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/13 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "22ccc38c266846cda6a93653f25a3f05"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./rogpt2-finetuned\",\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    save_strategy=\"epoch\",\n",
        "    fp16=True,  # use half-precision if GPU supports it\n",
        "    push_to_hub=False\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7EEKLfRMJ8c",
        "outputId": "d3b65a66-ff43-425d-cccb-b038612df58b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-92125620.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "Bt56y4VUNKwu",
        "outputId": "179bba55-1cb1-4106-90ea-f8f624658610"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 50257}.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlarisa-maria-muntean\u001b[0m (\u001b[33mlarisa-maria-muntean-babe-bolyai-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.22.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251105_134246-3eqtt1ya</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/larisa-maria-muntean-babe-bolyai-university/huggingface/runs/3eqtt1ya' target=\"_blank\">lyric-feather-3</a></strong> to <a href='https://wandb.ai/larisa-maria-muntean-babe-bolyai-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/larisa-maria-muntean-babe-bolyai-university/huggingface' target=\"_blank\">https://wandb.ai/larisa-maria-muntean-babe-bolyai-university/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/larisa-maria-muntean-babe-bolyai-university/huggingface/runs/3eqtt1ya' target=\"_blank\">https://wandb.ai/larisa-maria-muntean-babe-bolyai-university/huggingface/runs/3eqtt1ya</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='200' max='324' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [200/324 1:53:39 < 1:11:11, 0.03 it/s, Epoch 1.84/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='324' max='324' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [324/324 3:14:50, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=324, training_loss=1.8573529278790508, metrics={'train_runtime': 11746.739, 'train_samples_per_second': 0.028, 'train_steps_per_second': 0.028, 'total_flos': 300899025027072.0, 'train_loss': 1.8573529278790508, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('rogpt2-finetuned')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "i8xwyTxb-VJk",
        "outputId": "068b2f7b-2d44-4765-cd61-e69e46a06f7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_33a71953-5582-463e-b27b-0bb1a2ea915c\", \"rogpt2-finetuned\", 4096)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login()  # enter your Hugging Face API token\n",
        "\n",
        "model.push_to_hub(\"my-rogpt2-finetuned\")\n",
        "tokenizer.push_to_hub(\"my-rogpt2-finetuned\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214,
          "referenced_widgets": [
            "ad5812c12abe43bcb875d8db7a8ce213",
            "89c9e20388fd44caa194fba4bd76db3b",
            "74d0f3c2528f473596ab91ecc05cba6b",
            "183eec633c78404e85e8edf90c998467",
            "cdcca2c1d13e4b17b3614a3ff49dd4bf",
            "9204891e37c9472e942d1e07ec54e866",
            "e39d65b6659a4d4b8206916aba4aaa75",
            "e820c2c703474995b615ef34d857a885",
            "192b59bc2fce47b7934de4fda5c65462",
            "a41b1a121b40401ab43dc86ad3fe7d7e",
            "5ddb0d6c7d30445291f9e8507d37e07d",
            "db0a59f66b77494b8abf33d9d612c002",
            "ca6926108ebf4d7abcb2e584e960bc87",
            "81b2d55968cd47e88c54cdc129809c1f",
            "8617f06a177e47be8f1bbee182f9cc81",
            "2a18c2d69e9a4102a2034e2df0706f69",
            "de45144fe4934e049a7ed9e24875db5b",
            "f3a3d1dce257483896387c3694adc277",
            "ca7672baf2404f3e9f92ab66ae706e0e",
            "f6adc9c74c4e4957906a43a6806504f1",
            "3c4e4ff96d824a2db7a130f0b87f3e12",
            "1614fc2db2eb48cc908f0cd8700a6e75",
            "4a5f8531b37546debec9c01a2f1fbeda",
            "5500efa71bc44c12b6df10e5f0f22877",
            "aecc517279b24e76a341af9c4ca77978",
            "b11638a3bb0a411f889365bb4e129454",
            "36e61889b06d44299649a9199758707d",
            "3d23fb04547642f68c2cb145335b979c",
            "499d6b92e8954fb2839655b1b269da8f",
            "11f58937d6034536a29d1b989ce6ca41",
            "2afe8dfbfd474727b4b3455fc121ab0c",
            "4d67d68e18f74ed689ffdd85616b4197",
            "fca3b4253207460bbffc11b43d5c2fa6",
            "273a950a380349fdb67d0e3ea3bb8581",
            "50a4fb48dbb4449fb0e0d3493df02694",
            "4c2be4bd60f34d0286472e1268d90368",
            "a4814502b31a40b6a15a7b864e2e551a",
            "8abac361837c46d983fdb817c6068a88",
            "747fe4a2169941ca9c9cc92188b9ba5d",
            "5846b3b0028540d5878433dd37a53cc0",
            "a9ec4cdbdadb48e196520cb6c091c846",
            "b1352527eba14b0180c3a368900ecc9a",
            "110e4adb7c8a44d091fa34a591b76e38",
            "ec15b554e2ed464280bcade6d3689fd2",
            "634a4951689e48e38a67944876c3d839",
            "276c4b3695d94483bc3ee0e8a6c69dec",
            "18942f79265f4810a7e8b224c0569cb4",
            "907aa38b56c742a0bad3c7d4a201bf8c",
            "f2318ad4bbaa416796b82f9dcbe08144",
            "fe1adb59a6ae4824981a5c1b4ec5730a",
            "2d775597e950449a85b342d00694cb5e",
            "b6249e04fe3a45bdacf1871a0ef5219e",
            "5127639c595e4ba593747685eb011231",
            "4c1f6eb9037149d79b38aba230fa624a",
            "3f69c878f813429bb1f2ce902a155649",
            "8dd0c7374fc14ffab20098f5cbd39a07",
            "c0781a34c1674c24bfb2275387ec74a2",
            "4f7272f4a2e14f74952878d02fdb30d9",
            "39132149c70e41029d1a17614d03f164",
            "17cdfd1a34434939998c9d5d112d9401",
            "f3052b7b0a4e47778a64bedf4f033264",
            "54e9d644c10f43019e578d1092898bcd",
            "84eead0854944ee5b63e09a0493d7645",
            "5cbd1df70a5741fca927d4188ba2875b"
          ]
        },
        "id": "gudT--ieBIy5",
        "outputId": "d20ad029-47c8-4c32-99ac-85f4eb489bb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad5812c12abe43bcb875d8db7a8ce213"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f3a3d1dce257483896387c3694adc277"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "New Data Upload               : |          |  0.00B /  0.00B            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "499d6b92e8954fb2839655b1b269da8f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  ...zkojzyr/model.safetensors:   0%|          |  551kB / 1.42GB            "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5846b3b0028540d5878433dd37a53cc0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d775597e950449a85b342d00694cb5e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/lari631/my-rogpt2-finetuned/commit/e36de6be7fc42f8f2e59461ff3d7f666ebec52c1', commit_message='Upload tokenizer', commit_description='', oid='e36de6be7fc42f8f2e59461ff3d7f666ebec52c1', pr_url=None, repo_url=RepoUrl('https://huggingface.co/lari631/my-rogpt2-finetuned', endpoint='https://huggingface.co', repo_type='model', repo_id='lari631/my-rogpt2-finetuned'), pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"rogpt2-finetuned\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "ftf8dglt_nED",
        "outputId": "92f19de6-15f9-41b6-a402-303d6c407952"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8d5c4cf9-4be2-4fca-b176-ab58cf360465\", \"rogpt2-finetuned\", 4096)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "model.save_pretrained(\"/content/drive/MyDrive/rogpt2-finetuned\")\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/rogpt2-finetuned\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIePiVWGAftW",
        "outputId": "6b466b2e-053c-4d7a-ee78-29ed88b9aac4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/rogpt2-finetuned/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/rogpt2-finetuned/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/rogpt2-finetuned/vocab.json',\n",
              " '/content/drive/MyDrive/rogpt2-finetuned/merges.txt',\n",
              " '/content/drive/MyDrive/rogpt2-finetuned/added_tokens.json',\n",
              " '/content/drive/MyDrive/rogpt2-finetuned/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "\n",
        "model_path = \"./rogpt2-finetuned\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
        "\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "question = \"Generează un contract de închiriere\"\n",
        "prompt = f\"Întrebare: {question}\\nRăspuns:\"\n",
        "\n",
        "output = generator(\n",
        "    prompt,\n",
        "    max_new_tokens=200,     # adjust as needed\n",
        "    do_sample=True,         # for varied answers\n",
        "    temperature=0.7,        # 0.0 = deterministic, 1.0 = more random\n",
        "    top_p=0.9,              # nucleus sampling\n",
        "    pad_token_id=tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "print(output[0]['generated_text'])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzPyvq-gDkdt",
        "outputId": "39a5f5fd-10ae-428b-ab3e-aa994295f077"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Întrebare: Generează un contract de închiriere\n",
            "Răspuns: Contract de închiriere\n",
            "Acord de închiriere\n",
            "Răspuns: Contract de închiriere\n",
            "Acord de închiriere\n",
            "Art. 1. Obiectul contractului\n",
            "Obiectul prezentului contract îl constituie închirierea de către chiriaş, pe o perioadă de un an, a unui spaţiu de locuit şi a unui dependinţe, situat în_, în suprafaţă utilă de_mp, cu destinaţia de_mp, în suprafaţă utilă de_mp, în baza încheierii nr._ din data de_ a Adunării generale a proprietarilor.\n",
            "Art. 2. Durata contractului\n",
            "Art. 3. Drepturile şi obligaţiile părţilor\n",
            "Art. 4. Durata contractului\n",
            "Art. 5. Drepturile şi obligaţiile chiriaşului\n",
            "Art. 6. Obligaţiile chiriaşului\n",
            "Art. 7. Obligaţiile chiriaşului\n",
            "Art. 8. Durata contractului\n",
            "Art. 9. Drepturile şi obligaţiile chiriaşului\n",
            "Art. 10. Obligaţiile chiriaşului\n",
            "Art. 11. Obligaţiile proprietarului\n",
            "Art. 12. Obligaţiile chiriaşului\n",
            "Art. 13.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = generator(\n",
        "    prompt,\n",
        "    max_new_tokens=512,     # adjust as needed\n",
        "    do_sample=True,         # for varied answers\n",
        "    temperature=0.7,        # 0.0 = deterministic, 1.0 = more random\n",
        "    top_p=0.9,              # nucleus sampling\n",
        "    pad_token_id=tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "print(output[0]['generated_text'])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bbi1CW8CEJRp",
        "outputId": "ef583f99-8182-4940-d1e9-4e97bc7f04df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Întrebare: Generează un contract de închiriere\n",
            "Răspuns: Contract de închiriere\n",
            "Părţile contractului\n",
            "- S.C._, cu sediul în_, înregistrată în Registrul Comerţului_sub nr._, având cont bancar nr. _ deschis la _, reprezentată legal de către domnul_, domiciliat în_, identificat cu C.I._ seria_ nr._, eliberată de S.P.C.E.P._, la data de_, C.N.P._, în nume propriu,\n",
            "- S.C._, cu sediul în_, înregistrată în Registrul Comerţului_sub nr._, având cont bancar nr._ deschis la _, reprezentată legal de către domnul_, domiciliat în_, identificat cu C.I._ seria_ nr._, eliberată de S.P.C.E.P._, la data de_, C.N.P._, în nume propriu,\n",
            "- S.C._, cu sediul în_, înregistrată în Registrul Comerţului_sub nr._, având cont bancar nr._ deschis la_, reprezentată legal de către domnul_, domiciliat în_, identificat cu C.I._ seria_ nr._, eliberată de S.P.C.E.P._, la data de_, C.N.P._, în nume propriu,\n",
            "- S.C._, cu sediul în_, înregistrată în Registrul Comerţului_sub nr._, având cont bancar nr._ deschis la_, reprezentată legal de către domnul_, domiciliat în_, identificat cu C.I._ seria_ nr._, eliberată de S.P.C.E.P._, la data de_, C.N.P._, în nume propriu,\n",
            "- S.C._, cu sediul în_, înregistrată în Registrul Comerţului_sub nr._, având cont bancar nr._ deschis la_, reprezentată legal de către domnul_, domiciliat în_, identificat cu C.I._ seria_ nr._, eliberată de S.P.C.E.P._, la data de_, C.N.P._, în nume propriu,\n",
            "- S.C._, cu sediul în_, înregistrată în Registrul Comerţului_sub nr._, având cont bancar nr._ deschis la_, reprezentată legal de către domnul_, domiciliat în_, identificat cu C.I._ seria_ nr._, eliberată\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "question = \"Generează un contract de vânzare-cumpărare\"\n",
        "prompt = f\"Întrebare: {question}\\nRăspuns:\"\n",
        "\n",
        "output = generator(\n",
        "    prompt,\n",
        "    max_new_tokens=200,     # adjust as needed\n",
        "    do_sample=True,         # for varied answers\n",
        "    temperature=0.7,        # 0.0 = deterministic, 1.0 = more random\n",
        "    top_p=0.9,              # nucleus sampling\n",
        "    pad_token_id=tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "print(output[0]['generated_text'])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zCafNZBEstU",
        "outputId": "3f2f2653-dd65-4e67-d294-4f36ab615fc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Întrebare: Generează un contract de vânzare-cumpărare\n",
            "Răspuns: Contract de vânzare-cumpărare (MODEL)\n",
            "I. PĂRŢILE CONTRACTANTE\n",
            "1. NUME COMERCIANT 1, cetățean român, cu domiciliul în Mun. București, Str.... nr...., bl...., sc...., et...., ap...., sector..., identificat cu C.I. seria..., nr...., eliberată de S.P.C.E.P. Sector..., la data de..., C.N.P...., în nume propriu, în calitate de vânzător, şi\n",
            "2. NUME COMERCIANT 2, cetățean român, cu domiciliul în Mun. București, Str.... nr...., bl...., sc...., et...., ap...., sector..., identificat cu C.I. seria..., nr...., eliberată de S.P.C.E.P. Sector..., la data de..., C\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
}

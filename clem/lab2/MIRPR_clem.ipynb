{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZxAsL1cAeQHr"
   },
   "source": [
    "# Training ok\n",
    "\n",
    "Trained RO-GPT-2-medium on 5 sets of documents: cerere, procura, declaratie, testament and proces-verbal and computed perplexity score for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q7-GLOAS5JiV",
    "outputId": "2c80527a-1eb8-451f-f561-be7d7f71963f"
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets peft accelerate bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6cVHraPd6uar",
    "outputId": "ca3b9f27-86ec-470f-f572-bb5f7842e850"
   },
   "outputs": [],
   "source": [
    "!pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223,
     "referenced_widgets": [
      "c1bb5e74121648bda5b38ccbaa90516c",
      "1fc8a595c9c441d19eb5beff8418ca4c",
      "a9434013c83948a0b60ce08969944939",
      "70683f9174cf411682983be65f6ed79e",
      "957d720d4133481495226b5ee678e55f",
      "5337cf907a8141cf948d7603a80e04ac",
      "a0475dae9b0c4fc7bc4306aa549eca23",
      "a73138d88552404d8830933bbdc04669",
      "27a70aec59fd42ff9d05d9aca1bd672f",
      "9ee3ac3503bd4ba1958e0b960699a76a",
      "2bab03cffc1f486499caae31c1779647"
     ]
    },
    "id": "090ObSrX5OzY",
    "outputId": "b158f7dc-33fa-4941-b781-a7bffd4a3031"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from pathlib import Path\n",
    "\n",
    "dataset_path = \"/content/drive/MyDrive/Colab Notebooks/data\"\n",
    "\n",
    "# Load all text files recursively\n",
    "files = list(Path(dataset_path).rglob(\"*.txt\"))\n",
    "file_paths = [str(f) for f in files]\n",
    "\n",
    "dataset = load_dataset(\"text\", data_files=file_paths)\n",
    "dataset = dataset[\"train\"].train_test_split(test_size=0.2)\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "536c4ad4e50a46a0b6ca7c152254ebf4",
      "84f3e72636a64a969478cd8b23044223",
      "1f1f3d67973346b3a8203bde96756891",
      "317433da4b1a4c489560a59cb4f04a5e",
      "53e50390649c44d285f25599025646cd",
      "aee0eca604e9492a8e751c6a3d40f18c",
      "3f7024db90e84040aa21476b6c67ff89",
      "4a46e45ea34f4d66bbe17a9c1d1a555e",
      "bc0cc5f4a2e541cbbaf221aa822f993e",
      "8d25a181918a4b45a12bd8702acc87f1",
      "b8ab03bbc0424d329acb5c00f86e40a0",
      "e68a06c14e284b329a2482b52604d854",
      "1a2ce83e4c1441339e439c225da423ba",
      "3b54cc21349e4f64ac509d8e64aeac14",
      "f90c6d1336c24968b3ea2dbdea0b7e02",
      "19b30d69ea8f4738aabeedb9cdc77082",
      "de781ee5026a46dd98c00cb93b25b05a",
      "9d869982ee104b549e18eddab31ce051",
      "4d747ce6e73740aa94b1aabfaf817191",
      "5734078d5ee44991ac5b4e52d649d4ef",
      "b00650f16d584d549c7e98ad667d164a",
      "4467b52e20374cefa292a2a117ac9822"
     ]
    },
    "id": "67ND7qAs5hOe",
    "outputId": "f42f24f6-0470-4aea-b335-2c5edd0fec63"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"readerbench/RoGPT2-medium\")\n",
    "tokenizer.pad_token = tokenizer.eos_token  # GPT2 has no pad token\n",
    "\n",
    "def tokenize(example):\n",
    "    return tokenizer(example[\"text\"], truncation=True, max_length=512, padding=\"max_length\")\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JHykunwH6_o9"
   },
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    llm_int8_enable_fp32_cpu_offload=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0QUIk-x95jPQ",
    "outputId": "f3697989-84ac-4da1-fc0c-1a0c72ff634a"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "import torch\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"readerbench/RoGPT2-medium\",\n",
    "    device_map=\"auto\",       # folosește GPU automat\n",
    "    dtype=torch.float16,\n",
    "    offload_folder=\"offload\",\n",
    "    quantization_config=bnb_config,\n",
    ")\n",
    "\n",
    "# LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"c_proj\", \"c_attn\"],  # typical GPT2 projection layers\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GpoecC0K9gSf",
    "outputId": "9a00c1d6-020b-49c0-b203-560721655f22"
   },
   "outputs": [],
   "source": [
    "print(tokenized_dataset[\"train\"][1000])\n",
    "print(len(tokenized_dataset[\"train\"][0][\"input_ids\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "fAtsYdoO5j5J",
    "outputId": "02053936-e21e-4f69-c4c6-aa19d64554df"
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/content/drive/MyDrive/Colab Notebooks/ro-gpt2-legal\",\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=3,\n",
    "    logging_steps=50,\n",
    "    save_steps=200,\n",
    "    eval_steps=200,\n",
    "    save_total_limit=2,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=True,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dMsAtYYW5oTD",
    "outputId": "c9a297cf-7e1e-42aa-9a4d-9122f329929c"
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"/content/drive/MyDrive/Colab Notebooks/ro-gpt2-legal-final\")\n",
    "tokenizer.save_pretrained(\"/content/drive/MyDrive/Colab Notebooks/ro-gpt2-legal-final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MNXhWrlVcveX",
    "outputId": "ac497883-583f-4547-8e2f-5f3620324d2b"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/Colab Notebooks/ro-gpt2-legal-final\")\n",
    "my_model = AutoModelForCausalLM.from_pretrained(\"/content/drive/MyDrive/Colab Notebooks/ro-gpt2-legal-final\")\n",
    "\n",
    "def generate_doc(prompt, max_length=500):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    output = my_model.generate(\n",
    "        input_ids,\n",
    "        max_length=max_length,\n",
    "        do_sample=True,\n",
    "        temperature=0.2,\n",
    "        top_p=0.95,\n",
    "        no_repeat_ngram_size=2,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2sVF4SXlc4ht",
    "outputId": "92fdf647-4a18-4bd5-cfc9-7a9400f1e24b"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"PROCURĂ\n",
    "Subsemnata, ... (Nume mandantă), cetățean român, cu domiciliul în Mun. București, Sector ..., Str. ..., nr. ..., bl. ..., sc. ..., et. ..., ap. ..., identificată cu C.I. seria ..., nr. ..., eliberată de S.P.C.E.P. Sector ... la data de ..., valabilă până la data de ..., C.N.P. ..., prin prezenta împuternicesc pe doamna ... (Nume mandatară), cetățean român, cu domiciliul în Mun. București, Sector ..., Str. ..., nr. ..., bl. ..., sc. ..., et. ..., ap. ..., posesoare a C.I. seria ..., nr. ..., eliberat de S.P.C.E.P. Sector ... la data de ..., valabil până la data de ..., C.N.P. ..., pentru ca în numele meu şi pentru mine, să acţioneze cu depline puteri, în faţa autorităţilor şi instituţiilor publice, administrative, financiare, bancare, judecătoreşti etc., precum şi în faţa oricăror persoane fizice şi juridice, publice sau private, pentru a îndeplini, încheia şi executa orice acte de administrare şi conservare cu privire la toate bunurile mele mobile şi imobile din România, şi în general, pentru a mă reprezenta, susţine şi apăra drepturile şi interesele mele de orice fel.\n",
    "În executarea prezentului mandat, mandatara mea mă va putea reprezenta în orice fel de probleme, putând îndeplini orice fel de acte sau fapte, în numele meu şi pentru mine, după cum va considera necesar şi, în îndeplinirea prezentului mandat general, va putea îndeplini următoarele operaţiuni, dar fără a se limita la:\n",
    "         \"\"\"\n",
    "text = generate_doc(prompt)\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z7FmPI-VjVoG"
   },
   "outputs": [],
   "source": [
    "prompts = {\n",
    "   \"cerere\": \"\"\"\n",
    "    Domnule Preşedinte,\n",
    "\n",
    "Subsemnatul_, în calitate de_(reclamant sau, după caz, pârât, intervenient, apelant, recurent, revizuient,\n",
    "intimat etc.) în dosarul nr. / al acestei instanţe, cu termen de judecată la data de_, vă rog să\n",
    "\n",
    "\"\"\",\n",
    "    \"declaratie\": \"\"\"DECLARAȚIE\n",
    "Subsemnata ..., cetăţean român, cu domiciliul în municipiul București, str. ... nr. ..., bl. ..., sc. ..., et. ..., ap. ..., sector ..., identificată cu C.I. seria ..., nr. ... eliberată de S.P.C.E.P. Sector ..., la data de ..., C.N.P. ..., în nume propriu, declar următoarele:\n",
    "\n",
    "\"\"\",\n",
    "    \"testament\":\"\"\"TESTAMENT\n",
    "\n",
    "          Subsemnatul .......... domiciliat în .........., CNP .........,[1]dispun prin prezentul testament  următoarele:\n",
    "\"\"\",\n",
    "    \"proces_verbal\":\"\"\"\n",
    "PROCES-VERBAL DE AUDIERE MINOR\n",
    "\n",
    "[2]\n",
    "\n",
    "CU VÂRSTA DE PESTE 10 ANI\n",
    "\n",
    "          Azi, data de ..........., în faţa mea........, notar public, în cadrul procedurii de\n",
    "\"\"\",\n",
    "    \"procura\":\"\"\"PROCURĂ SPECIALĂ\n",
    "\n",
    "Subsemnatul NUME MANDANT, cetățean român, domiciliat în municipiul București, str. ..., nr. ..., bl.3, sc. ..., et. ..., ap. ..., sector 1, identificat cu Carte de Identitate seria ..., nr. ..., eliberată de S.P.C.E.P. Sector 1, la data de ..., C.N.P...., împuternicesc prin prezenta pe domnul NUME MANDATAR, cetățean român, domiciliat în municipiul București, str. ..., nr. ..., bl. ..., sc. ..., et. ..., ap. ..., sector 1, posesor al C.I., seria ..., nr. ..., eliberată de S.P.C.E.P. Sector 1, la data de ..., C.N.P...., ca în numele meu şi pentru mine să se prezinte şi să mă reprezinte, cu puteri depline în vederea îndeplinirii tuturor formalităţilor necesare înmatriculării și înregistrării fiscale și obținerii plăcuțelor cu numere de înmatriculare (pe numele meu ca nou proprietar) privind autoturismul marca ..., număr de identificare ..., an fabricație ..., cu obligația de a face dovada calității mele de nou proprietar.\n",
    "\tÎn îndeplinirea mandatului de faţă, mandatarul meu este împuternicit, să întocmească\n",
    "\"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L7d80qZEj4x1",
    "outputId": "c1dee206-0390-4a85-d17b-771d95cd5fa0"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "base_dir = Path(\"/content/drive/MyDrive/Colab Notebooks/generated_docs\")\n",
    "for doc_type,prompt in prompts.items():\n",
    "    print(f\"Generating {doc_type}...\")\n",
    "\n",
    "    for i in range(1, 6):\n",
    "        text = generate_doc(prompt)\n",
    "        clean_text = text.replace(\"\\n\\n\", \"\\n\").strip()\n",
    "        output_path = base_dir / doc_type / f\"{doc_type}_{i}.txt\"\n",
    "        with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(clean_text)\n",
    "    print(f\"Saved 5 {doc_type} documents in {base_dir/doc_type}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m9oiOUiAZg5l",
    "outputId": "76aa9494-6bf7-47aa-9573-40cc9315fe4d"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "model_path = '/content/drive/MyDrive/Colab Notebooks/ro-gpt2-legal-final'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "if device != -1:\n",
    "    model.to(f'cuda:{device}')\n",
    "\n",
    "\n",
    "perplexity_pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=device)\n",
    "\n",
    "def compute_perplexity(text):\n",
    "    enc = tokenizer(text, return_tensors=\"pt\")\n",
    "    enc = {k: v.to(model.device) for k, v in enc.items()}\n",
    "    with torch.no_grad():\n",
    "        loss = model(**enc, labels=enc[\"input_ids\"]).loss\n",
    "    return math.exp(loss.item())\n",
    "\n",
    "doc_types = [\"proces_verbal\", \"procura\", \"cerere\", \"declaratie\", \"testament\"]\n",
    "base_gen = Path('/content/drive/MyDrive/Colab Notebooks/generated_docs')\n",
    "for doc_type in doc_types:\n",
    "    scores = []\n",
    "    for file in (base_gen / doc_type).glob(\"*.txt\"):\n",
    "        with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "            txt = f.read().strip()\n",
    "            if len(txt.split()) > 10:\n",
    "                try:\n",
    "                    scores.append(compute_perplexity(txt))\n",
    "                except:\n",
    "                    continue\n",
    "    if scores:\n",
    "        avg = np.mean(scores)\n",
    "        print(f\"{doc_type.upper()} average perplexity: {avg:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SOnlV9Odd9p4"
   },
   "source": [
    "# Too long of a training\n",
    "\n",
    "Tried training RO-LLAMA-2-7B using LoRa, but the training would last 2 months and a half."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QAnJzw_6iRPp",
    "outputId": "76619598-352f-488a-d515-b03a3ba4ed88"
   },
   "outputs": [],
   "source": [
    "!pip install transformers torch accelerate bitsandbytes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4fpeP3xuNgWS",
    "outputId": "0a940374-5700-4ff7-c6b4-0c7c550ea47d"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # True dacă GPU e activ\n",
    "print(torch.cuda.get_device_name(0))  # Numele GPU-ului\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l_VZdZzDjRsa"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YHmgD-76chIg"
   },
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    llm_int8_enable_fp32_cpu_offload=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 525,
     "referenced_widgets": [
      "e32837c3b6b6443b90f504fba5edeeec",
      "6de32a32df1f4a769d2367c2f16c6601",
      "f701b81c738e438b9ebe2593f510e1d7",
      "86abb2e171104e8bbb0bddc539d395fb",
      "924b91baf1c2445db8832367a65fb551",
      "79311a680b174817b59fd3bdc8d90f4f",
      "be32e69a9eaa41759f6f08c9ca7e56e0",
      "50a71496e0eb46cf80bff318ef8ef002",
      "d84270a725ce43189b77c771a4338c37",
      "4045f7072a85482199cd59490a787542",
      "4fe3aa2b4c3e40109711cb4525ea487e",
      "ebeb6d4b399a4c3eaf3b59c29b1caad0",
      "3f160d45f3ef45829aa85cfe42f1a836",
      "7a94725c34444b729767d9113241926f",
      "dab6d1c02355488ca5139f21f6899d0f",
      "db8bf978f6654bb88d14e813554e211a",
      "9c55cc0eb08c459c8624e73cce5e2e6a",
      "894e0af95eca4218bd6a824dc016b41f",
      "c20cf744031c481dbf756cf44fc1985a",
      "42d3f1b161754d50823dad50ceee6484",
      "b1d69934c7194ab98d4ede917aa55303",
      "603fdce9f2bb4d93abe96b7aecaa89b5",
      "529833fbe6374723860578f4696ca6d8",
      "ed0d173dde7c4b2eadcf94c3301b45fe",
      "ec000a6fdbfd459d91cb38ac63a82cd9",
      "baffdfd8cc124275a6a55186f0536b20",
      "9179375963124016951b6a59b970ca3f",
      "ab418acfb4ca4b2dac62327af639ce73",
      "15494dc98d7a4e96a56b607a9eddc8ed",
      "4baf069af9b14d178576812aa202e0d9",
      "8bd1d21daab64790825d2165712c13fb",
      "0bf5e6f3ddca4000b2494b9cd2f9e95a",
      "ecc3cdf604664db1968d954c74753974",
      "5bfe34c8df64441eb5a8b78de91e0ad8",
      "b8f2137119914c7786d4b98d9ccef355",
      "a7379194458d4443add5c00bbf422afa",
      "81ebef5eb514481cb50f7de5ec54b496",
      "69264145144649ff9caf5af520021718",
      "52440c7f5b844f62993394b1b4820975",
      "f249946588754c7f93c4f171c3e2273e",
      "0c8f2b9def0f4ef4b7f9e2b1d33408a0",
      "6697506227264285b92a0f5feec44ad6",
      "e8496b581bf143b094e54d49a90f270e",
      "64bbd37528914e529e00130c8da1e1ca",
      "7c67264421f8433dbe39a431b017e41c",
      "35e4dd1e8bc54246ac8eb464113ae23e",
      "a1ca4d53ce5d426f93283a244fa0a908",
      "08a4ee138d584abfbfc2c617dc6bfdb7",
      "f84bb88a9d9848c5995bd377f0551c3d",
      "6283c26f8ec04b7b8a9ed3548008a393",
      "c96008bc4ad44ca1b3d613a3cd0452f3",
      "a66be5231e2f4af1b797cc679a42b4f5",
      "b877c8f445ef4d6c8ba90f8ecb53fb5d",
      "ab48d164c95a4ddcadef4f81e2c52227",
      "e867b8d858ee4d6faf94d41cd17ef6ee",
      "dd8777f71e254276bc1f1eb67c6c3636",
      "b5801742a90247958a4b4146dd5eec90",
      "d567a32e71664efb8cf9fe5e625798e2",
      "049b651e1d5941c8a101194deb5f0753",
      "d21fb565dabc415892d62fcf8569b191",
      "11fff76f3e4842d382dbc96e6f2d9154",
      "fa421f14f45d4933aba48c641c91930f",
      "92a282f2c10540dfbc5dbfa9588f6a96",
      "8c3124035687403f92bafa5346df1b9f",
      "917b58e7c2584c9dbaa5fab798d9ea83",
      "02498e1bdd7d44c1899adbe59ff004c1",
      "9a9fd76a94584b7eb967f942b53f3ea2",
      "e961b7335eea4793bd25a631fa598cf1",
      "5f8d77b7005f42869583573bdd6974d6",
      "0089fddea0cd47759c5ebdcffb142985",
      "21c6879a2e014877a2bfadc3bec2e98d",
      "6a2392fecc7c40baa55179620c4d55fb",
      "fe26ed5fe39f4ab493d848f11b34a398",
      "5c4b656d698e4bd3849d2d1d94385831",
      "809b11b3fcd34372860e2195c7823fba",
      "0010510651eb42fcacc13015b58b23f4",
      "bf7ff593f58f4323af58eba321028be2",
      "f8e3f2ed26b64760a965d89611cd341d",
      "b03e490a0f8f4660a5482505232f16bf",
      "63190ff71c8d4be99987c09e7503e91f",
      "d488d8c8a9884214b5293680efbc27b2",
      "5270ef2f777042bd971ffbdbb4340441",
      "283584ac4d9146b3a2246f718161708c",
      "65912e1bf5fb416d878bee07ac36e3f2",
      "791d05e62b354023bdd77f517063a714",
      "1a9c2590f99e499ca11a29efa9b627eb",
      "ddb67b36a82949f78260dac2c58dc2a6",
      "82f9995584ce43dd924682a28822c191",
      "a3eb7feb30cc44f8ac70ac2d917c5b32",
      "29f9fea8b9b645b9acb5059439ab0e59",
      "e6b997042f304407b1fd858ac1ce0797",
      "21bbbc4ecfa846d7b48015d4a93c0b5e",
      "3f778316be484eefa1af3d9c4d363144",
      "52a65bbcf74e432398c4b858947f2677",
      "d409eeb3e8344635b2d8dff38dd4285d",
      "5cf6ef2c9d264e82bb1c87c838405e47",
      "28a45ad8688841829ce16f2ea9d9ac6d",
      "94af7c08a6264ef18e831fe2cbcb6d50",
      "fd5f2728a0fd48a19e0b52d78c1d5285",
      "c808bc3b551a4078bd63cc94e5189a57",
      "2125bb5bf912433cb78ed6bd556831c6",
      "afa042bdd7704d81b7b4b6efb8dca6cb",
      "5cd6963967f14e6a897330e161df2e20",
      "fe2d774769a04affa234b80583a2de13",
      "cfa98bb88eee40b0a169b885cd6f860f",
      "be7c6bb15a094e78900b962cf02b6c17",
      "9391cadcced147ccb23fb447be50d83e",
      "6b4195c34b384beca699c4aa5146c0f2",
      "45843b4283a54879826a2fe9ba0723a1",
      "3fc570b4126c46958075f297448ca402",
      "e6cdab11a68c451cbf8065589a49ca8b",
      "b4aa2c2f29f64922b461df834fed8642",
      "7dba8e93600e45519e2785957aadf4b4",
      "90d16b949c0944d0beffca9d098339e6",
      "238dbbd8a6934652bbb783e63d59ed41",
      "bc6d65da3c814637abba79e35c71c17d",
      "b22fea7c9a2c4effb1528d251eac7f7d",
      "7dc11cc870584bfab078bdf95d0d8e53",
      "c5492a450197490a97247a1653294e2b",
      "dcecaba7f94041de8529f187466f9f46",
      "b3fbd72ce65248b6932790d32f15af37",
      "f61d046ad570420185726132664d4b54",
      "c17ffd0524e24a01a770ba6161dd305a",
      "7ee0b367fb784d2da353dfa804c4b593",
      "c17b2551a892482ebb156c4d737088db",
      "23f8cb6caafe4a85bfc330336a1a7f3f",
      "883e172f0abc4975911103b54902e069",
      "253a281336ff448c8df82f48ed170be3",
      "a7e204633f6f4d9ca4705ce5616e5b26",
      "4f57ed5ef82d49809b7f11fbb9a4bcd0",
      "329e0c6cf0fa4bbea948041cb0685ded",
      "87746726615442ecbeef19a188413a5c"
     ]
    },
    "id": "zghUIEWAIc6T",
    "outputId": "7e9abbbd-e3be-40f5-9ef3-3f7f9069965b"
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"OpenLLM-Ro/RoLlama2-7b-Base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    device_map=\"auto\",       # folosește GPU automat\n",
    "    dtype=torch.float16,\n",
    "    offload_folder=\"offload\",\n",
    "    quantization_config=bnb_config,\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lUpFEY1mTd0L"
   },
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\",\"v_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104,
     "referenced_widgets": [
      "cb30a8a6e3ba4dcf8208ecd8cf82cda2",
      "54713903337c42b48386f2db1041c1e0",
      "e9e1f0db29c04d56ad4621e60f70a389",
      "a2599e27a3e240a3b93a01348c034a25",
      "4a6fe05b91c54db4ab1d5239c20f5e10",
      "73257c6373214240875bf021cd81b7a7",
      "38f398e50e0145a9bb9949f642d65e7c",
      "10a781b8bdc44f7db6ec8e26488e6e11",
      "af783fe7ef75428a8b599329f130554e",
      "9a0d3c511d474e5ba7848354f3b93239",
      "bd59e8e734dd4e3c881f0b31d3979d09"
     ]
    },
    "id": "bMRXdKFxTqS9",
    "outputId": "bacdcddf-238f-49ad-87ac-2148c65dcc92"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "dataset_path = \"/content/drive/MyDrive/Colab Notebooks/jurisprudenta.txt\"\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Dacă fișierul are o propoziție/document per linie\n",
    "dataset = load_dataset(\"text\", data_files={\"train\": dataset_path})\n",
    "\n",
    "print(dataset[\"train\"][0:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "51fde466b68b47a4802971a4f6c52b24",
      "d828576e10004ccdb1d2974749d6349a",
      "7bc8162212904bffa44e56d233488f0b",
      "a50f4feab0ce49e6b39c438a0fa22858",
      "c9e1abca628d49698174ad3fcaf29404",
      "8b6eeaa986db49d194f2e4974a745327",
      "351699371b9d4e0590d17f021f6e4b0f",
      "7be1057d4bbb4838b1a4577c05d1724e",
      "544621c5d7b440c588bfe393e09d424d",
      "80f44d5b59e043bcaf18f1083b870ae9",
      "5aa183c90f6d4c28907f8afcb9ae6bfe"
     ]
    },
    "id": "URS3MMGkV7DT",
    "outputId": "0a4d317c-222b-4a67-944b-e3b9e34860b9"
   },
   "outputs": [],
   "source": [
    "def tokenize_fn(example):\n",
    "    return tokenizer(example[\"text\"], truncation=True, max_length=1024)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_fn, batched=True, remove_columns=[\"text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r7eDw6wGYBx1"
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False  # Causal LM, nu Masked LM\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F7nWzQQHXpiM"
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./juridical_lora\",\n",
    "    per_device_train_batch_size=1,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=True,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=50,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "model.save_pretrained(\"./juridical_lora\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iozsLx60eICf"
   },
   "source": [
    "# Useful encoder-decoder\n",
    "\n",
    "Found bert-legal-romanian-cased-v1 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YUDQieSZuqXT",
    "outputId": "8c897e57-ad32-4e3d-f4be-33a39a3262ba"
   },
   "outputs": [],
   "source": [
    "!pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PGh5JpSTuw4c",
    "outputId": "6664c890-db61-49b7-e665-138f39991185"
   },
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"snisioi/bert-legal-romanian-cased-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IitEBOR8uzlF",
    "outputId": "235d4155-69b6-476d-e812-9b1b1ad373ce"
   },
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"snisioi/bert-legal-romanian-cased-v1\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"snisioi/bert-legal-romanian-cased-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sImZxxZ1u1fw"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "output_dir = Path(\"/content/drive/MyDrive/Colab Notebooks/generated_docs\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z7Mtnlwt2ZRq"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "MODEL_NAME = \"readerbench/RoGPT2-medium\"\n",
    "DOC_TYPES = [\"cerere\", \"declaratie\", \"testament\", \"proces_verbal\"]\n",
    "OUTPUT_DIR = Path(\"/content/drive/MyDrive/Colab Notebooks/generated_docs\")\n",
    "NUM_PER_TYPE = 1  # number of docs to generate per type\n",
    "MAX_LENGTH = 700  # max tokens per generation\n",
    "\n",
    "PROMPTS = {\n",
    "    \"cerere\": \"CERERE\\nSubsemnata_, domiciliată în_\",\n",
    "    \"declaratie\": \"DECLARAȚIE\\nSubsemnata_, cetățean român, cu domiciliul în_\",\n",
    "    \"testament\": \"TESTAMENT\\nSubsemnata_, cu domiciliul în_\",\n",
    "    \"proces_verbal\": \"PROCES VERBAL\\nSubsemnatul_, reprezentant al_\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9wKx0fAM2dVh"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "COAnGMg12iav"
   },
   "outputs": [],
   "source": [
    "def safe_filename(name):\n",
    "    # make lowercase, replace spaces with hyphens\n",
    "    return name.lower().replace(\" \", \"_\") + \".txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R7rEz66cxDqo",
    "outputId": "ca3b2657-c3a9-4e5d-b86f-fff8f690dd66"
   },
   "outputs": [],
   "source": [
    "for doc_type in DOC_TYPES:\n",
    "    prompt = PROMPTS[doc_type]\n",
    "    for i in range(1, NUM_PER_TYPE + 1):\n",
    "        inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "        generated = model.generate(\n",
    "            inputs,\n",
    "            max_length=MAX_LENGTH,\n",
    "            no_repeat_ngram_size=4,\n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "            temperature=0.3\n",
    "        )\n",
    "        text = tokenizer.decode(generated[0], skip_special_tokens=True)\n",
    "\n",
    "        file_path = OUTPUT_DIR / doc_type / safe_filename(f\"{doc_type}_{i}_temp_03\")\n",
    "        file_path.write_text(text, encoding=\"utf-8\")\n",
    "        print(f\"✅ Generated {file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "SOnlV9Odd9p4",
    "iozsLx60eICf"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
